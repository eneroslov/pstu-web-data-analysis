{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYEkraKd-JaL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "12yCbU4N-M3g"
      },
      "outputs": [],
      "source": [
        "def download_images_to_zip(url, zip_name, min_resolution=(100, 100), max_resolution=(2000, 2000)):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    img_urls = set()\n",
        "\n",
        "    for img_tag in soup.find_all(['img', 'source']):\n",
        "        src = img_tag.get('src') or img_tag.get('data-src') or img_tag.get('srcset')\n",
        "        if src:\n",
        "            img_urls.add(src)\n",
        "\n",
        "    img_urls = [img if img.startswith('http') else f\"{url}/{img}\" for img in img_urls]\n",
        "\n",
        "    total_downloaded = 0\n",
        "    with zipfile.ZipFile(zip_name, 'w') as zipf:\n",
        "        for i, img_url in enumerate(img_urls):\n",
        "            try:\n",
        "                img_response = requests.get(img_url)\n",
        "\n",
        "                img = Image.open(BytesIO(img_response.content))\n",
        "\n",
        "                if min_resolution[0] <= img.size[0] <= max_resolution[0] and \\\n",
        "                   min_resolution[1] <= img.size[1] <= max_resolution[1]:\n",
        "\n",
        "                    img_format = 'JPEG' if img.mode == 'RGB' else 'PNG'\n",
        "                    img_name = f\"image_{i}.{img_format.lower()}\"\n",
        "\n",
        "                    with BytesIO() as img_bytes:\n",
        "                        img.save(img_bytes, format=img_format)\n",
        "                        zipf.writestr(img_name, img_bytes.getvalue())\n",
        "                    total_downloaded += 1\n",
        "            except Exception as e:\n",
        "                print(f\"Ошибка при загрузке {img_url}: {e}\")\n",
        "\n",
        "    print(f\"Всего скачано изображений: {total_downloaded}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "E9tVhHuW-UMv"
      },
      "outputs": [],
      "source": [
        "def create_yolo_dataset_from_zip(zip_path, dataset_path, split_ratio=(0.8, 0.2)):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zipf:\n",
        "        img_files = zipf.namelist()\n",
        "        random.shuffle(img_files)\n",
        "\n",
        "        train_path = os.path.join(dataset_path, 'train/images')\n",
        "        val_path = os.path.join(dataset_path, 'val/images')\n",
        "        os.makedirs(train_path, exist_ok=True)\n",
        "        os.makedirs(val_path, exist_ok=True)\n",
        "\n",
        "        total_images = len(img_files)\n",
        "        train_count = int(total_images * split_ratio[0])\n",
        "        val_count = total_images - train_count\n",
        "\n",
        "        for i, img_file in enumerate(img_files):\n",
        "            target_dir = train_path if i < train_count else val_path\n",
        "            with zipf.open(img_file) as img_src:\n",
        "                with open(os.path.join(target_dir, img_file), 'wb') as img_dst:\n",
        "                    img_dst.write(img_src.read())\n",
        "\n",
        "        print(f\"Количество изображений в тренировочном датасете: {train_count}\")\n",
        "        print(f\"Количество изображений в валидационном датасете: {val_count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vFRTQp5M-WhV",
        "outputId": "578d09ab-0b81-42f8-eda3-fc73f43e6fbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Всего скачано изображений: 60\n",
            "Количество изображений в тренировочном датасете: 48\n",
            "Количество изображений в валидационном датасете: 12\n"
          ]
        }
      ],
      "source": [
        "url = 'https://scryfall.com/search?q=(e%3Altr+cn%3E%3D452)+or+(e%3Altc+cn%3E%3D411)&order=set&as=grid&unique=prints'\n",
        "zip_name = 'images.zip'\n",
        "dataset_path = 'yolo_dataset'\n",
        "\n",
        "download_images_to_zip(url, zip_name, min_resolution=(200, 200), max_resolution=(1000, 1000))\n",
        "\n",
        "create_yolo_dataset_from_zip(zip_name, dataset_path, split_ratio=(0.8, 0.2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLW7sbpJ_al9",
        "outputId": "fc6fecd3-3ada-4b0e-acf9-aa10169cd3d3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "def delete_dataset_and_zip(zip_path, dataset_path):\n",
        "    if os.path.exists(zip_path):\n",
        "        os.remove(zip_path)\n",
        "\n",
        "    if os.path.exists(dataset_path):\n",
        "        shutil.rmtree(dataset_path)\n",
        "\n",
        "delete_dataset_and_zip(zip_name, dataset_path)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
