{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install requests bs4 graphviz pymorphy3 googletrans"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suh5au4HolMJ",
        "outputId": "037585bf-14fb-4737-ccdf-0301893ac811"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.10/dist-packages (0.0.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: pymorphy3 in /usr/local/lib/python3.10/dist-packages (2.0.2)\n",
            "Requirement already satisfied: googletrans in /usr/local/lib/python3.10/dist-packages (4.0.0rc1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4) (4.12.3)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from pymorphy3) (0.7.2)\n",
            "Requirement already satisfied: pymorphy3-dicts-ru in /usr/local/lib/python3.10/dist-packages (from pymorphy3) (2.4.417150.4580142)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.10/dist-packages (from googletrans) (0.13.3)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (2024.9.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (1.3.1)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (3.0.4)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (1.5.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans) (0.9.1)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.10/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (3.2.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (3.0.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4) (2.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3V-4NQsrmvLQ"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "from graphviz import Digraph\n",
        "import pymorphy3\n",
        "from googletrans import Translator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Инициализация морфологического анализатора и переводчика.\n",
        "morph = pymorphy3.MorphAnalyzer()\n",
        "translator = Translator()\n",
        "\n",
        "# MediaWiki API URL.\n",
        "WIKI_API_URL = \"https://ru.wikipedia.org/w/api.php\""
      ],
      "metadata": {
        "id": "OYcDxUHC94ap"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для поиска статьи и получения её контента.\n",
        "def get_wiki_page_content(title):\n",
        "    params = {\n",
        "        \"action\": \"query\",\n",
        "        \"prop\": \"extracts|links|images\",\n",
        "        \"titles\": title,\n",
        "        \"format\": \"json\",\n",
        "        \"explaintext\": 1,\n",
        "        \"pllimit\": \"max\",\n",
        "        \"imlimit\": \"max\"\n",
        "    }\n",
        "    response = requests.get(WIKI_API_URL, params=params)\n",
        "    data = response.json()\n",
        "    pages = data['query']['pages']\n",
        "\n",
        "    # Извлекаем первую страницу (она единственная в ответе).\n",
        "    page = next(iter(pages.values()))\n",
        "\n",
        "    # Получаем основной текст и связанные узлы (ссылки).\n",
        "    content = {\n",
        "        \"title\": page.get(\"title\"),\n",
        "        \"text\": page.get(\"extract\", \"\"),\n",
        "        \"links\": [link['title'] for link in page.get(\"links\", [])],\n",
        "        \"images\": [image['title'] for image in page.get(\"images\", [])]\n",
        "    }\n",
        "\n",
        "    return content"
      ],
      "metadata": {
        "id": "4DhvCaQX-F_G"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для построения графа в формате DOT.\n",
        "def build_dot_graph(data):\n",
        "    dot = Digraph(comment='Wikimedia Articles Graph')\n",
        "\n",
        "    # Добавляем узлы и связи.\n",
        "    for node, content in data.items():\n",
        "        dot.node(node, node)\n",
        "        for link in content['links']:\n",
        "            if link in data:  # Добавляем связь только с известными узлами.\n",
        "                dot.edge(node, link)\n",
        "\n",
        "    return dot"
      ],
      "metadata": {
        "id": "dhvWu5mN-NQH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для сбора данных и создания графа.\n",
        "def collect_wiki_data(subject, limit=30):\n",
        "    visited = set()\n",
        "    to_visit = [subject]\n",
        "    articles_data = {}\n",
        "\n",
        "    while to_visit and len(articles_data) < limit:\n",
        "        current_subject = to_visit.pop(0)\n",
        "        if current_subject in visited:\n",
        "            continue\n",
        "\n",
        "        print(f\"Fetching article: {current_subject}\")\n",
        "        content = get_wiki_page_content(current_subject)\n",
        "        articles_data[current_subject] = content\n",
        "        visited.add(current_subject)\n",
        "\n",
        "        # Добавляем ссылки на другие статьи в очередь для посещения.\n",
        "        to_visit.extend([link for link in content['links'] if link not in visited and link not in to_visit])\n",
        "\n",
        "    return articles_data"
      ],
      "metadata": {
        "id": "o3wETZncA21s"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для автоматического перевода текста на русский (если статья на другом языке).\n",
        "def translate_text(text, dest='ru'):\n",
        "    translated = translator.translate(text, dest=dest)\n",
        "    return translated.text"
      ],
      "metadata": {
        "id": "UuNNbTwPCKcF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subject = \"Чёрная металлургия\"  # Начальная статья.\n",
        "articles_data = collect_wiki_data(subject)\n",
        "\n",
        "# Сохраняем данные в формате JSON.\n",
        "with open('wiki_data.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(articles_data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "# Создаем граф в формате DOT.\n",
        "dot_graph = build_dot_graph(articles_data)\n",
        "\n",
        "# Сохраняем граф.\n",
        "dot_graph.render('wiki_graph.dot', view=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "id": "NcqyDzLfA71F",
        "outputId": "d3a60b31-fdc1-4aed-9868-16a16a89be3f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching article: Чёрная металлургия\n",
            "Fetching article: Arcelor Mittal\n",
            "Fetching article: Gerdau\n",
            "Fetching article: POSCO\n",
            "Fetching article: Tata Steel\n",
            "Fetching article: Techint\n",
            "Fetching article: U.S. Steel\n",
            "Fetching article: Wayback Machine\n",
            "Fetching article: Австралия\n",
            "Fetching article: Агломерат (металлургия)\n",
            "Fetching article: Агломерационная машина\n",
            "Fetching article: Агломерационная фабрика\n",
            "Fetching article: Агломерация (металлургия)\n",
            "Fetching article: Азовсталь\n",
            "Fetching article: Алюминиевая промышленность\n",
            "Fetching article: Алюминотермия\n",
            "Fetching article: Аносов, Павел Петрович\n",
            "Fetching article: Антрацит\n",
            "Fetching article: Аргентина\n",
            "Fetching article: Аффинаж\n",
            "Fetching article: Байков, Александр Александрович\n",
            "Fetching article: Бардин, Иван Павлович\n",
            "Fetching article: Бессемер, Генри\n",
            "Fetching article: Бессемеровский процесс\n",
            "Fetching article: Блюминг (стан)\n",
            "Fetching article: Брикет (металлургия)\n",
            "Fetching article: Брикетный пресс\n",
            "Fetching article: Вакууматор\n",
            "Fetching article: Вакуумная металлургия\n",
            "Fetching article: Великая Отечественная война\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'wiki_graph.dot.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}